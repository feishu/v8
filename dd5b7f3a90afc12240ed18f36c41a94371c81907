{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "61f884e1_76753b1c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 12
      },
      "lineNbr": 0,
      "author": {
        "id": 1115935
      },
      "writtenOn": "2024-11-06T14:15:18Z",
      "side": 1,
      "message": "LGTM with comments.",
      "revId": "dd5b7f3a90afc12240ed18f36c41a94371c81907",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e3af9c4d_26bd0a01",
        "filename": "src/objects/string.cc",
        "patchSetId": 12
      },
      "lineNbr": 761,
      "author": {
        "id": 1115935
      },
      "writtenOn": "2024-11-06T14:15:18Z",
      "side": 1,
      "message": "This would be more robust if written as `DCHECK_LE(offset, this-\u003elength() - length)`, because the `offset + length` computation could overflow for bad offsets, whereas the subtraction cannot underflow given the previous DCHECK.",
      "range": {
        "startLine": 761,
        "startChar": 12,
        "endLine": 761,
        "endChar": 43
      },
      "revId": "dd5b7f3a90afc12240ed18f36c41a94371c81907",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "8d98b053_c77283d5",
        "filename": "src/objects/string.cc",
        "patchSetId": 12
      },
      "lineNbr": 761,
      "author": {
        "id": 1519522
      },
      "writtenOn": "2024-11-07T13:43:15Z",
      "side": 1,
      "message": "Ah yes, good point!",
      "parentUuid": "e3af9c4d_26bd0a01",
      "range": {
        "startLine": 761,
        "startChar": 12,
        "endLine": 761,
        "endChar": 43
      },
      "revId": "dd5b7f3a90afc12240ed18f36c41a94371c81907",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "eddd1455_9c07e683",
        "filename": "src/objects/string.cc",
        "patchSetId": 12
      },
      "lineNbr": 798,
      "author": {
        "id": 1115935
      },
      "writtenOn": "2024-11-06T14:15:18Z",
      "side": 1,
      "message": "This feels a bit expensive. Maybe that\u0027s OK for the use case... but how would you feel about something like:\n```\n  uint32_t encoded_length \u003d unibrow::Utf8::Encode(result + pos, character, last);\n  // \"LT\" to account for the eventual null terminator.\n  SBXCHECK_LT(encoded_length, capacity - pos);\n  pos +\u003d encoded_length;\n```\nIn the worst case (concurrently-mutated string exceeding the previously computed capacity), this would write OOB by 3 bytes (4 byte max encoding length, at least 1 byte remaining after the check in the previous iteration), but it would then terminate the process before the OOB write can cause any further confusion.",
      "range": {
        "startLine": 798,
        "startChar": 4,
        "endLine": 798,
        "endChar": 76
      },
      "revId": "dd5b7f3a90afc12240ed18f36c41a94371c81907",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "53549a75_d80066c7",
        "filename": "src/objects/string.cc",
        "patchSetId": 12
      },
      "lineNbr": 798,
      "author": {
        "id": 1519522
      },
      "writtenOn": "2024-11-07T08:55:17Z",
      "side": 1,
      "message": "Right, I also considered something like that, but was a bit concerned because (a) we\u0027d then be dependent on SBXCHECK crashing very quickly and without the attacker being able to delay it, which is probably fine, but a bit subtle, but also because (b) I think our fuzzers will just spam us with these reports. I have an experimental fuzzer using PKEYs to intercept and modify sandbox memory reads, and it finds this issue trivially on a single core in a few minutes (because ASAN of course catches this OOB write).\n\nSome alternatives I could think of:\n* Encode into a temporary stack buffer and to a memcpy afterwards. Maybe a bit faster (?) but definitely still some overhead\n* Allocate the output buffer also inside the sandbox. This might be nice, but we don\u0027t currently have the infrastructure for that, mainly because `delete` would magically need to somehow find the in-sandbox memory allocator.\n* Overallocate the output buffer by 3 bytes. Maybe this is the best tradeoff if we care about CPU overhead and not so much about memory overhead.\n\nIn general, this function probably isn\u0027t super performance critical, but I\u0027m also happy to e.g. try the overallocation approach. WDYT?",
      "parentUuid": "eddd1455_9c07e683",
      "range": {
        "startLine": 798,
        "startChar": 4,
        "endLine": 798,
        "endChar": 76
      },
      "revId": "dd5b7f3a90afc12240ed18f36c41a94371c81907",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "edd156a0_d94d211b",
        "filename": "src/objects/string.cc",
        "patchSetId": 12
      },
      "lineNbr": 798,
      "author": {
        "id": 1115935
      },
      "writtenOn": "2024-11-07T09:34:15Z",
      "side": 1,
      "message": "Ah, yes, fuzzer report spam is a convincing argument against my suggestion.\n\nExtending your list:\n- \"option 1.5\" (as a hybrid of the first two) would be to build the string into an on-heap `ByteArray`, and then in the end do a single huge `memcpy` into the off-heap `result` array.\n- in the fullness of time, I expect that we\u0027ll eventually implement UTF-8 strings as a first-class string representation, but it\u0027s very much unclear how many years away from that we currently are. Once we have such infrastructure, we can reuse it here.\n\nOverall I don\u0027t feel strongly about it. Keeping the CL as-is sounds acceptable. Overallocating by 3 bytes also sounds fine; you could also document that idea in a comment so we can get back to it if the need arises in the form of unfortunate performance results on some benchmark/workload.",
      "parentUuid": "53549a75_d80066c7",
      "range": {
        "startLine": 798,
        "startChar": 4,
        "endLine": 798,
        "endChar": 76
      },
      "revId": "dd5b7f3a90afc12240ed18f36c41a94371c81907",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "43180f26_550852c2",
        "filename": "src/objects/string.cc",
        "patchSetId": 12
      },
      "lineNbr": 798,
      "author": {
        "id": 1519522
      },
      "writtenOn": "2024-11-07T13:43:15Z",
      "side": 1,
      "message": "Okay, yeah I\u0027ve added a comment now. I\u0027ve also now done some quick local benchmarking (with the new %StringToCString, but slightly modified so it doesn\u0027t allocate an ArrayBuffer and just returns the output_length as Smi), and the overhead of the check seems negligible: maybe we go from 5.51s to 5.52s on the test I constructed (encoding of a long string with mixed 1-byte and 4-byte UTF8 chars). But I\u0027ll watch out for any performance regressions after landing it.\nI\u0027ve also now added a regression test, and for that we also need to avoid any memory corruption, otherwise ASAN will immediately complain.",
      "parentUuid": "edd156a0_d94d211b",
      "range": {
        "startLine": 798,
        "startChar": 4,
        "endLine": 798,
        "endChar": 76
      },
      "revId": "dd5b7f3a90afc12240ed18f36c41a94371c81907",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}